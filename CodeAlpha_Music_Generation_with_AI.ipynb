{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSG_3pq1U_4p"
      },
      "source": [
        "# AI-Powered Music Generation\n",
        "This notebook demonstrates an AI-powered music generation system using Recurrent Neural Networks (RNNs) with LSTM layers. The system is capable of composing original music based on the patterns it learns from the provided dataset of audio files.\n",
        "\n",
        "## Installation\n",
        "First, let's install the necessary packages.\n",
        "```python\n",
        "!pip install numpy pandas tensorflow music21 pydub librosa\n",
        "```\n"
      ],
      "id": "KSG_3pq1U_4p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiZay48aU_4t"
      },
      "outputs": [],
      "source": [
        "!pip install numpy pandas tensorflow music21 pydub librosa\n"
      ],
      "id": "SiZay48aU_4t"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJRHdtDYU_4v"
      },
      "source": [
        "## Step 1: Import Libraries\n",
        "Let's import the necessary libraries for this project."
      ],
      "id": "TJRHdtDYU_4v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y8aoABIU_4w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "from pydub import AudioSegment\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense, Activation\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "id": "8Y8aoABIU_4w"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp-c6mdUU_4y"
      },
      "source": [
        "## Step 2: Convert MP3 to WAV\n",
        "We need to convert the MP3 file to WAV format for easier processing."
      ],
      "id": "pp-c6mdUU_4y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeM8vUkxU_4z"
      },
      "outputs": [],
      "source": [
        "# Convert MP3 to WAV\n",
        "def convert_mp3_to_wav(mp3_path, wav_path):\n",
        "    audio = AudioSegment.from_mp3(mp3_path)\n",
        "    audio.export(wav_path, format=\"wav\")\n",
        "\n",
        "# Paths\n",
        "mp3_path = '/content/Kcee - Ojapiano (Official Video).mp3'\n",
        "wav_path = '/content/temp_audio.wav'\n",
        "\n",
        "# Convert\n",
        "convert_mp3_to_wav(mp3_path, wav_path)"
      ],
      "id": "WeM8vUkxU_4z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNdbqMq_U_40"
      },
      "source": [
        "## Step 3: Extract Musical Features\n",
        "We will extract features from the WAV file using the `librosa` library."
      ],
      "id": "XNdbqMq_U_40"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ytsi3ksAU_42"
      },
      "outputs": [],
      "source": [
        "# Extract musical features\n",
        "def extract_features(wav_path):\n",
        "    y, sr = librosa.load(wav_path)\n",
        "    tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "    rmse = librosa.feature.rms(y=y)\n",
        "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "    zcr = librosa.feature.zero_crossing_rate(y)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "    features = np.concatenate((chroma_stft, rmse, spec_cent, spec_bw, rolloff, zcr, mfcc))\n",
        "    return features\n",
        "\n",
        "# Extract features\n",
        "features = extract_features(wav_path)"
      ],
      "id": "Ytsi3ksAU_42"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjIbnR_aU_45"
      },
      "source": [
        "## Step 4: Prepare Sequences\n",
        "We will prepare sequences from the extracted features to be used as input for the model."
      ],
      "id": "YjIbnR_aU_45"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtmrNLieU_47"
      },
      "outputs": [],
      "source": [
        "# Prepare sequences\n",
        "sequence_length = 100\n",
        "n_vocab = features.shape[0]\n",
        "\n",
        "network_input = []\n",
        "network_output = []\n",
        "\n",
        "for i in range(len(features[0]) - sequence_length):\n",
        "    seq_in = features[:, i:i + sequence_length]\n",
        "    seq_out = features[:, i + sequence_length]\n",
        "    network_input.append(seq_in)\n",
        "    network_output.append(seq_out)\n",
        "\n",
        "n_patterns = len(network_input)\n",
        "\n",
        "network_input = np.reshape(network_input, (n_patterns, sequence_length, n_vocab))\n",
        "network_input = network_input / np.max(network_input)\n",
        "network_output = np.reshape(network_output, (n_patterns, n_vocab))\n",
        "network_output = network_output / np.max(network_output)"
      ],
      "id": "WtmrNLieU_47"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh52o4c7U_48"
      },
      "source": [
        "## Step 5: Define the Model\n",
        "We will define and compile the LSTM model."
      ],
      "id": "Dh52o4c7U_48"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_TwHr-IU_4-"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(512))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(n_vocab))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ],
      "id": "Q_TwHr-IU_4-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERKOralkU_4_"
      },
      "source": [
        "## Step 6: Train the Model\n",
        "We will train the model on the prepared sequences."
      ],
      "id": "ERKOralkU_4_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2ZcufnDU_4_"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(network_input, network_output, epochs=10, batch_size=64)\n",
        "\n",
        "# Save the model\n",
        "model.save('music_generation_model.h5')"
      ],
      "id": "q2ZcufnDU_4_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRl7-O_CU_5A"
      },
      "source": [
        "## Step 7: Generate Music\n",
        "We will use the trained model to generate new music."
      ],
      "id": "xRl7-O_CU_5A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_eczUI_U_5A"
      },
      "outputs": [],
      "source": [
        "# Generate new music\n",
        "def generate_notes(model, network_input, n_vocab, sequence_length):\n",
        "    start = np.random.randint(0, len(network_input)-1)\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    for note_index in range(500):\n",
        "        prediction_input = np.reshape(pattern, (1, len(pattern), n_vocab))\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "        prediction_output.append(prediction[0])\n",
        "        pattern = np.vstack((pattern[1:], prediction))\n",
        "\n",
        "    return prediction_output\n",
        "\n",
        "# Example usage\n",
        "prediction_output = generate_notes(model, network_input, n_vocab, sequence_length)"
      ],
      "id": "p_eczUI_U_5A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUx1N7JkU_5B"
      },
      "source": [
        "## Step 8: Convert Prediction to MIDI\n",
        "We will convert the generated sequence back to a MIDI file."
      ],
      "id": "lUx1N7JkU_5B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b7Jh4i_U_5B"
      },
      "outputs": [],
      "source": [
        "# Convert prediction to MIDI file\n",
        "def create_midi(prediction_output, output_file):\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    for pattern in prediction_output:\n",
        "        new_note = note.Note()\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp=output_file)\n",
        "\n",
        "# Example usage\n",
        "create_midi(prediction_output, 'generated_music.mid')"
      ],
      "id": "9b7Jh4i_U_5B"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFC8GI9WU_5B"
      },
      "source": [
        "The generated music will be saved as `generated_music.mid`."
      ],
      "id": "HFC8GI9WU_5B"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}